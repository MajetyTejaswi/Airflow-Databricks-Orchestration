name: Sync DAGs to S3

on:
  push:
    branches:
      - main
    paths:
      - 'airflow-dags/**'
  workflow_dispatch:

env:
  AWS_REGION: us-east-1

jobs:
  sync-dags-to-s3:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get S3 bucket name
        id: get-bucket
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          S3_BUCKET="airflow-dags-${AWS_ACCOUNT_ID}-${AWS_REGION}"
          echo "bucket=$S3_BUCKET" >> $GITHUB_OUTPUT
          echo "S3 DAGs Bucket: $S3_BUCKET"

      - name: Sync DAGs to S3
        run: |
          S3_BUCKET="${{ steps.get-bucket.outputs.bucket }}"
          
          echo "Syncing DAGs to s3://${S3_BUCKET}/dags/"
          
          aws s3 sync airflow-dags/ "s3://${S3_BUCKET}/dags/" \
            --exclude "*" \
            --include "*.py" \
            --delete
          
          echo "âœ“ DAGs synced to S3"
          
          echo "Current DAGs in S3:"
          aws s3 ls "s3://${S3_BUCKET}/dags/"
